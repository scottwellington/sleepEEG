{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenient logging imports\n",
    "import logging\n",
    "import importlib\n",
    "importlib.reload(logging) # see https://stackoverflow.com/a/21475297/1469195\n",
    "log = logging.getLogger()\n",
    "log.setLevel('INFO')\n",
    "import sys\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s : %(message)s',level=logging.INFO, stream=sys.stdout)\n",
    "\n",
    "# Functional imports\n",
    "import mne\n",
    "import os\n",
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "import braindecode\n",
    "import sklearn\n",
    "import pdb\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import argparse\n",
    "import time\n",
    "import warnings\n",
    "import itertools\n",
    "import ast\n",
    "import pyedflib\n",
    "import GPUtil\n",
    "import yaml\n",
    "\n",
    "# Utility imports\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules.utils import _pair, _triple\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from io import StringIO\n",
    "from mne.time_frequency import psd_welch\n",
    "from scipy.signal import butter, filtfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Architectures\n",
    "\n",
    "class FCN(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                layers=1,\n",
    "                input_size=1,\n",
    "                output_size=1,\n",
    "                dropout=.5\n",
    "                ):\n",
    "\n",
    "        super(FCN, self).__init__()\n",
    "        input = input_size[0]*input_size[1]\n",
    "        output = int((output_size[0] + input)/2)\n",
    "        d = OrderedDict()\n",
    "        idx = 0\n",
    "        for i in range(layers-1):\n",
    "            d[str(idx)] = nn.Linear(input, output)\n",
    "            d[str(idx+1)] = nn.BatchNorm1d(output)\n",
    "            d[str(idx+2)] = nn.LeakyReLU()\n",
    "            d[str(idx+3)] = nn.Dropout(dropout)\n",
    "            input = output\n",
    "            output = int((output_size[0] + input)/2)\n",
    "            idx += 4\n",
    "        d[str(idx)] = nn.Linear(input, output_size[0])\n",
    "        d[str(idx+1)] = nn.Softmax() # different nonlinearity in last layer\n",
    "        self.feedforward = nn.Sequential(d)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.feedforward(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                in_channels=(1,1),\n",
    "                out_channels=(1,1),\n",
    "                input_size=(1,1),\n",
    "                kernel_size=(1,1),\n",
    "                pool_size=(1,1),\n",
    "                stride=(1,1),\n",
    "                dilation=(1,1),\n",
    "                padding=(0,0),\n",
    "                dropout=.5\n",
    "                ):\n",
    "    \n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = input_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool_size = pool_size\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.padding = padding\n",
    "        \n",
    "        in_1, in_2, in_3 = self.in_channels\n",
    "        out_1, out_2, out_3 = self.out_channels\n",
    "\n",
    "        #Convolution 1\n",
    "        self.cnn1 = nn.Conv2d(in_1, out_1, self.kernel_size, stride=self.stride, dilation=self.dilation, padding=self.padding)\n",
    "        #Batch Normalisation 1\n",
    "        self.bn1 = nn.BatchNorm2d(out_1)\n",
    "        #Activation function 1\n",
    "        self.leakyrelu1 = nn.LeakyReLU()\n",
    "        #Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=self.pool_size)\n",
    "        #Convolution 2\n",
    "        self.cnn2 = nn.Conv2d(in_2, out_2, self.kernel_size, stride=self.stride, dilation=self.dilation, padding=self.padding)\n",
    "        #Batch Normalisation 2\n",
    "        self.bn2 = nn.BatchNorm2d(out_2)\n",
    "        #Activation function 2\n",
    "        self.leakyrelu2 = nn.LeakyReLU()\n",
    "        #Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=self.pool_size)\n",
    "        #Convolution 3\n",
    "        self.cnn3 = nn.Conv2d(in_3, out_3, self.kernel_size, stride=self.stride, dilation=self.dilation, padding=self.padding)\n",
    "        #Batch Normalisation 3\n",
    "        self.bn3 = nn.BatchNorm2d(out_3)\n",
    "        #Activation function 3\n",
    "        self.leakyrelu3 = nn.LeakyReLU()\n",
    "        #Max pool 3\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=self.pool_size)\n",
    "        #Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "        #Feedforward network following convolutions+maxpooling\n",
    "        self.feedforward = nn.Sequential(        \n",
    "            nn.Linear(2160,1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(512,256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(256,128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(128,64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(64,32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(32,16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(16,8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(8,4),\n",
    "            )\n",
    "            \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        #Batch norm 1\n",
    "        out = self.bn1(out)\n",
    "        #Activation 1\n",
    "        out = self.leakyrelu1(out)\n",
    "        #Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "        #Convolution 2\n",
    "        out = self.cnn2(out)\n",
    "        #Batch norm 2\n",
    "        out = self.bn2(out)\n",
    "        #Activation 2\n",
    "        out = self.leakyrelu2(out)\n",
    "        #Max pool 2\n",
    "        out = self.maxpool2(out)\n",
    "        #Convolution 3\n",
    "        out = self.cnn3(out)\n",
    "        #Batch norm 3\n",
    "        out = self.bn3(out)\n",
    "        #Activation 3\n",
    "        out = self.leakyrelu3(out)\n",
    "        #Max pool 3\n",
    "        out = self.maxpool3(out)\n",
    "        #Resize\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #Dropout\n",
    "        out = self.dropout(out)\n",
    "        #Feedforward\n",
    "        out = self.feedforward(out)\n",
    "        return out\n",
    "\n",
    "class CNN3d(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                in_channels=1,\n",
    "                out_channels=1,\n",
    "                input_size=(1,1),\n",
    "                kernel_size=(1,1),\n",
    "                pool_size=(1,1),\n",
    "                stride=(1,1),\n",
    "                dilation=(1,1),\n",
    "                padding=(0,0),\n",
    "                dropout=.5\n",
    "                ):\n",
    "    \n",
    "        super(CNN3d, self).__init__()\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.input_size = input_size\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.padding = padding\n",
    "        self.pool_size = pool_size\n",
    "        \n",
    "        in_1, in_2, in_3 = self.in_channels\n",
    "        out_1, out_2, out_3 = self.out_channels\n",
    "        \n",
    "        #Convolution 1\n",
    "        self.cnn1 = nn.Conv3d(in_1, out_1, self.kernel_size, stride=self.stride, dilation=self.dilation, padding=self.padding)\n",
    "        #Batch Normalisation 1\n",
    "        self.bn1 = nn.BatchNorm3d(out_1)\n",
    "        #Activation function 1\n",
    "        self.leakyrelu1 = nn.LeakyReLU()\n",
    "        #Max pool 1\n",
    "        self.maxpool1 = nn.MaxPool3d(kernel_size=self.pool_size)    \n",
    "        #Convolution 2\n",
    "        self.cnn2 = nn.Conv3d(in_2, out_2, self.kernel_size, stride=self.stride, dilation=self.dilation, padding=self.padding)\n",
    "        #Batch Normalisation 2\n",
    "        self.bn2 = nn.BatchNorm3d(out_2)\n",
    "        #Activation function 2\n",
    "        self.leakyrelu2 = nn.LeakyReLU()\n",
    "        #Max pool 2\n",
    "        self.maxpool2 = nn.MaxPool3d(kernel_size=self.pool_size)\n",
    "        #Convolution 3\n",
    "        self.cnn3 = nn.Conv3d(in_3, out_3, self.kernel_size, stride=self.stride, dilation=self.dilation, padding=self.padding)\n",
    "        #Batch Normalisation 3\n",
    "        self.bn3 = nn.BatchNorm3d(out_3)\n",
    "        #Activation function 3\n",
    "        self.leakyrelu3 = nn.LeakyReLU()\n",
    "        #Max pool 3\n",
    "        self.maxpool3 = nn.MaxPool3d(kernel_size=self.pool_size)\n",
    "        #Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        #Feedforward network following convolutions+maxpooling\n",
    "        self.feedforward = nn.Sequential(        \n",
    "            nn.Linear(3312,1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024,512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(512,256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(256,128),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(128,64),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(64,32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(32,16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(16,8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(8,4),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        #Convolution 1\n",
    "        out = self.cnn1(x)\n",
    "        #Batch norm 1\n",
    "        out = self.bn1(out)\n",
    "        #Activation 1\n",
    "        out = self.leakyrelu1(out)\n",
    "        #Max pool 1\n",
    "        out = self.maxpool1(out)\n",
    "        #Convolution 2\n",
    "        out = self.cnn2(out)\n",
    "        #Batch norm 2\n",
    "        out = self.bn2(out)\n",
    "        #Activation 2\n",
    "        out = self.leakyrelu2(out)\n",
    "        #Max pool 2\n",
    "        out = self.maxpool2(out)\n",
    "        #Convolution 3\n",
    "        out = self.cnn3(out)\n",
    "        #Batch norm 3\n",
    "        out = self.bn3(out)\n",
    "        #Activation 3\n",
    "        out = self.leakyrelu3(out)\n",
    "        #Max pool 3\n",
    "        out = self.maxpool3(out)\n",
    "        #Resize\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #Dropout\n",
    "        out = self.dropout(out)\n",
    "        #Feedforward\n",
    "        out = self.feedforward(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                in_channels=1,\n",
    "                out_channels=1,\n",
    "                input_size=(1,1),\n",
    "                kernel_size=(1,1),\n",
    "                padding=(1,1),\n",
    "                layers=1,\n",
    "                dropout=.5,\n",
    "                ):\n",
    "        \n",
    "        super(CNNLSTM, self).__init__()\n",
    "        \n",
    "        self.__dict__.update(locals())\n",
    "        del self.self\n",
    "        \n",
    "        in_1, in_2 = self.in_channels\n",
    "        out_1, out_2 = self.out_channels\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_1, out_1, kernel_size=self.kernel_size,padding=self.padding)\n",
    "        self.conv2 = nn.Conv2d(in_2, out_2, kernel_size=self.kernel_size,padding=self.padding)\n",
    "        self.conv2_drop = nn.Dropout2d(self.dropout)\n",
    "        #self.fc1 = nn.Linear(320, 50)\n",
    "        #self.fc2 = nn.Linear(50, 10)\n",
    "        self.rnn = nn.LSTM(input_size=72, hidden_size=48, num_layers=self.layers, batch_first=True)\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(48,32),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(32,16),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),            \n",
    "            nn.Linear(16,8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(8,4),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.unsqueeze(-1)\n",
    "        #batch_size, timesteps, C, H, W = x.size()\n",
    "        batch_size, H, W, timesteps, C = x.size()\n",
    "        #x = x.view(batch_size * timesteps, C, H, W)\n",
    "        x = x.view(batch_size * timesteps, H, W, C)\n",
    "        x = nn.functional.relu(nn.functional.max_pool2d(self.conv1(x), 2))\n",
    "        x = nn.functional.relu(nn.functional.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.dropout(x, training=self.training)\n",
    "        # x = self.fc2(x)\n",
    "        # return F.log_softmax(x, dim=1)\n",
    "        x = x.view(batch_size, timesteps, -1)\n",
    "        x, (h_n, h_c) = self.rnn(x)\n",
    "        x = self.feedforward(x[:, -1, :])\n",
    "        return x\n",
    "    \n",
    "class Models:\n",
    "\n",
    "    def __init__(self, **parameters):\n",
    "        \n",
    "        if parameters:\n",
    "            self.model = model = parameters['model']\n",
    "            chans = len(parameters['channels'])\n",
    "            freqs = len(parameters['frequency_bands'])\n",
    "            time = parameters['window_size']\n",
    "            crop = parameters['crop_size']\n",
    "            drop = parameters['dropout']\n",
    "\n",
    "        else: # initial call with values==0 prior to args\n",
    "            model=chans=freqs=time=crop=drop = 0\n",
    "    \n",
    "        self.models = {\n",
    "            'FCN':{\n",
    "                'layers':5,\n",
    "                'input_size':(crop,chans*freqs),\n",
    "                'output_size':(crop,),\n",
    "                'dropout':drop,\n",
    "                },\n",
    "            'CNN':{\n",
    "                'in_channels':(chans,chans*2), #(layer 1, layer 2)\n",
    "                'out_channels':(chans*2,chans*3), #(layer 1, layer 2)\n",
    "                'input_size':(chans,freqs,time),\n",
    "                'kernel_size':_pair(3),\n",
    "                'pool_size':_pair(2),\n",
    "                'stride':_pair(1),\n",
    "                'dilation':_pair(1),\n",
    "                'padding':_pair(1),\n",
    "                'dropout':drop,\n",
    "                },\n",
    "            'CNN3d':{\n",
    "                'in_channels':(chans,chans*2), #(layer 1, layer 2)\n",
    "                'out_channels':(chans*2,chans*3), #(layer 1, layer 2)\n",
    "                'input_size':(chans,freqs,time,1),\n",
    "                'kernel_size':(3,3,1), # depth, height, width,\n",
    "                'pool_size':_triple(2),\n",
    "                'stride': _triple(1),\n",
    "                'dilation':_triple(1),\n",
    "                'padding':_triple(1),\n",
    "                'dropout':drop,\n",
    "                },\n",
    "            'CNNLSTM':{\n",
    "                'in_channels':(chans,chans*2), # cnn layer 1, cnn layer 2,\n",
    "                'out_channels':(chans*2,chans*3), # cnn layer 1, cnn layer 2,\n",
    "                'input_size':(time,freqs,8,16),\n",
    "                'kernel_size':_pair(3),\n",
    "                'padding':_pair(2),\n",
    "                'layers':3,\n",
    "                'dropout':drop,\n",
    "                },\n",
    "        }\n",
    "    \n",
    "        for i in parameters:\n",
    "            if i in self.models[model] and parameters[i]: # if parameter evaluates to True:\n",
    "                self.models[model][i] = parameters[i] # overwrite (with arg flag); otherwise, use default value\n",
    "    \n",
    "    def get_model(self):\n",
    "\n",
    "        model = eval(self.model)(**self.models[self.model]) # call class instance with its parameters\n",
    "\n",
    "        return self.models[self.model]['input_size'], model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform class for data preprocessing, windowing (and cropping) and reshaping for model architectures.\n",
    "\n",
    "class Transform:\n",
    "    \n",
    "    '''\n",
    "    Takes the physionet EEG sleep stage data and does online preprocessing.\n",
    "    Note that this is pretty bad practice for signal processing: much better\n",
    "    to have the files preprocessed and saved, and run those batches through\n",
    "    the network with a simple np.load. However, for our purposes, this will do.\n",
    "    '''    \n",
    "\n",
    "    def __init__(self,\n",
    "        model_name = None,\n",
    "        channels_transform = False,\n",
    "        frequency_bands_transform = False,\n",
    "        eeg_indices = []\n",
    "        ):\n",
    "    \n",
    "        self.model_name = model_name\n",
    "        self.channels_transform = channels_transform # either all channels, or EEG channels only\n",
    "        self.frequency_bands_transform = frequency_bands_transform # either all frequency bands, or high gamma only\n",
    "        self.eeg_indices = lambda x: np.array([x[i,:,:] for i in eeg_indices]) # legacy; just in case the channels are unlabelled and we need to select these by index only\n",
    "\n",
    "        # Map the channel (sensor) names to their data types\n",
    "        # (just ensures MNE knows know to process these properly):\n",
    "        self.mapping = {\n",
    "                'EEG Fpz-Cz': 'eeg',\n",
    "                'EEG Pz-Oz': 'eeg',\n",
    "                'EOG horizontal': 'eog',\n",
    "                'Resp oro-nasal': 'resp',\n",
    "                'EMG submental': 'emg',\n",
    "                'Temp rectal': 'misc',\n",
    "                'Event marker': 'stim',\n",
    "                }\n",
    "\n",
    "        # reminder of order: ['delta','theta','alpha','sigma','beta','gamma']\n",
    "\n",
    "        self.freq_bands = {\n",
    "                \"delta\": [0.5, 4.5],\n",
    "                \"theta\": [4.5, 8.5],\n",
    "                \"alpha\": [8.5, 11.5],\n",
    "                \"sigma\": [11.5, 15.5],\n",
    "                \"beta\": [15.5, 32.5],\n",
    "                \"gamma\": [32.5, 49.5],\n",
    "                }\n",
    "\n",
    "\n",
    "        # From annotations.description, we can see that we have 7 classes. One of these classes\n",
    "        # is the 'unknown' class ('Sleep stage ?'), so we'll disregard this and assign the others:\n",
    "        self.event_ids = {'Sleep stage W': 0,\n",
    "                'Sleep stage 1': 1,\n",
    "                'Sleep stage 2': 1,\n",
    "                'Sleep stage 3': 2,\n",
    "                'Sleep stage 4': 2,\n",
    "                'Sleep stage R': 3,\n",
    "                }\n",
    "\n",
    "        self.fs = 100 # hardcode cheat; we already know the data is at 100 Hz\n",
    "    \n",
    "        self.window_transforms = {\n",
    "        'CNN':lambda X,y : (X, y), # D x H x W = sensors x freqbands x samples\n",
    "        'CNN3d':lambda X,y : (np.moveaxis(np.split(X,np.shape(X)[1],axis=1),[0,1,2,3],[1,0,3,2]), y), # 128x5x256x1\n",
    "        #'Deep4Net':lambda X,y : (np.expand_dims(X.T,-1),y),\n",
    "        'CNNLSTM':lambda X,y : (np.moveaxis(np.split(X,int(np.shape(X)[2]/2)),[0,1,2,3],[1,3,2,0]), y), # 256x5x2x64\n",
    "        }\n",
    "        self.cropped_window_transforms = {\n",
    "        'CNN':lambda X,y,_z : (X,y), # D x H x W = sensors x freqbands x samples\n",
    "        'CNN3d':lambda X,y,_z : (X,y), # D x H x W = sensors x freqbands x samples\n",
    "        'FCN':lambda X,y,_z : (X,y),\n",
    "        }\n",
    "\n",
    "    def window_transform(self, input, target):\n",
    "        \n",
    "        input = np.split(input,5,axis=1) # separate out the frequency bands\n",
    "        input = np.moveaxis(input, [0,1,2], [1,2,0]) # change to (channels x frequency bands x samples)\n",
    "        \n",
    "        if self.channels_transform: # extract brocas area\n",
    "            input = self.brocas_area(input)\n",
    "        if self.frequency_bands_transform: # extract high gamma\n",
    "            input = np.swapaxes([input[:,-1,:]],0,1)\n",
    "\n",
    "        target = np.reshape(target,-1)\n",
    "        \n",
    "        if self.model_name not in self.window_transforms:\n",
    "            X, y = input.reshape(-1), target\n",
    "        else:\n",
    "            X, y = self.window_transforms[self.model_name](input, target)\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "    def cropped_window_transform(self, input, target, **sliding):\n",
    "    \n",
    "        X_start = sliding['idx'] * sliding['scaling_factor']\n",
    "        X_end = (sliding['idx'] + sliding['length']) * sliding['scaling_factor']\n",
    "        y_start = sliding['idx']\n",
    "        y_end = sliding['idx'] + sliding['length']\n",
    "\n",
    "        input, target = input[:,:,:,X_start:X_end], target#[y_start:y_end]\n",
    "        \n",
    "        X, y = self.cropped_window_transforms[self.model_name](input, target, sliding['length'])\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def epoch(self, input, target):\n",
    "\n",
    "        eeg = mne.io.read_raw_edf(input) #, preload=True, stim_channel='auto')\n",
    "        annotations = mne.read_annotations(target)\n",
    "\n",
    "        eeg.set_annotations(annotations, emit_warning=False)\n",
    "        eeg.set_channel_types(self.mapping)\n",
    "\n",
    "        # Top-and-tail the waking data to remove class immbalances. We'll only keep 1/100th of this class:\n",
    "\n",
    "        first100 = annotations.onset[1]/100\n",
    "        last100 = (annotations.onset[-1]-annotations.onset[-2])/100\n",
    "        annotations.crop(annotations[1]['onset'] - first100, annotations[-2]['onset'] + last100)\n",
    "\n",
    "        eeg.set_annotations(annotations, emit_warning=False) # Set the event ids:\n",
    "\n",
    "        # EPOCHING! First use MNE's built-in convenience function to epoch (chunk) the data according to the event:\n",
    "        events = mne.events_from_annotations(eeg, event_id=self.event_ids, chunk_duration=30.)\n",
    "\n",
    "        # Then for the sake of getting a classification report later, we merge sleep stages 3 & 4:\n",
    "        self.event_ids_merged = {'Sleep stage W': 0,\n",
    "                'Sleep stage 1/2': 1,\n",
    "                'Sleep stage 3/4': 2,\n",
    "                'Sleep stage R': 3,\n",
    "                }\n",
    "\n",
    "        # self.event_ids_merged = {'Sleep stage W': 0,\n",
    "        #         'Sleep stage 1': 1,\n",
    "        #         'Sleep stage 2': 2,\n",
    "        #         'Sleep stage 3': 3,\n",
    "        #         'Sleep stage 4': 4,\n",
    "        #         'Sleep stage R': 5,\n",
    "        #         }\n",
    "\n",
    "        deltas = [abs(j-i) for i,j in zip(annotations.onset, annotations.onset[1:])] # List of time differences between all sleep stages\n",
    "        tmax = 30. - 1. / eeg.info['sfreq'] # Only chunk in steps of 0 to 29.99 secs\n",
    "\n",
    "        picks = 'eeg' if self.channels_transform else ['eeg','eog','emg','resp','misc']\n",
    "\n",
    "        epochs = mne.Epochs(raw=eeg, events=events[0], event_id=self.event_ids_merged,\n",
    "            tmin=0., tmax=tmax, baseline=None, picks=picks) # Get epochs:\n",
    "\n",
    "        return epochs\n",
    "\n",
    "    def butter_bandpass_filter(self, data, lowcut, highcut, order=5):\n",
    "        # Adapted from https://stackoverflow.com/questions/12093594/how-to-implement-band-pass-butterworth-filter-with-scipy-signal-butter\n",
    "        nyq = 0.5 * self.fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        b, a = butter(order, [low, high], btype='band')\n",
    "        y = filtfilt(b, a, data, axis=0)\n",
    "        return y\n",
    "\n",
    "    def subband_decomposition(self, eeg_data):\n",
    "        \"\"\" Takes in a single subject dictionary (where the keys are runs)\n",
    "        Returns a dictionary of dictionaries, where the keys of the sub-\n",
    "        dictionaries are EEG bands.\n",
    "        \"\"\"\n",
    "        filtered_data = []\n",
    "\n",
    "        for filter in self.freq_bands.keys():\n",
    "            low = self.freq_bands[filter][0]\n",
    "            high = self.freq_bands[filter][1]\n",
    "            filtered_data.append(self.butter_bandpass_filter(eeg_data,low,high))\n",
    "\n",
    "        filtered_data = np.array(filtered_data)\n",
    "        filtered_data = np.moveaxis(filtered_data,[0,1,2,3],[2,0,1,3]) # reshape data to be (eventsxsensorsxfreqsxtime)\n",
    "        #filtered_data = np.expand_dims(filtered_data, axis=0)\n",
    "        # note: reshape data to be (eventsxfreqsxsensorsxtime) = [1,0,2,3]\n",
    "        # note: reshape data to be (eventsxsensorsxfreqsxtime) = [2,0,1,3]\n",
    "\n",
    "        if len(args.frequency_bands)==1:\n",
    "            filtered_data = filtered_data[:,:,[*self.freq_bands.keys()].index(args.frequency_bands[0]),:] # just extract the signal of interest\n",
    "\n",
    "        return(filtered_data)\n",
    "\n",
    "    def power_spectral_decomposition(self, eeg_data):\n",
    "\n",
    "        psds, freqs = psd_welch(eeg_data, fmin=0.5, fmax=49.5) # Welch PSD (EEG only)\n",
    "        psds /= np.sum(psds, axis=-1, keepdims=True) # Normalize the PSDs\n",
    "\n",
    "        X = []\n",
    "\n",
    "        for fmin, fmax in self.freq_bands.values():\n",
    "            psds_band = psds[:, :, (freqs >= fmin) & (freqs < fmax)].mean(axis=-1)\n",
    "            X.append(psds_band.reshape(len(psds), -1))\n",
    "\n",
    "        return np.concatenate(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-rendering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch classes for loading the data, batching, and running the network.\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, input_paths, target_paths, transform=False):\n",
    "        \n",
    "        self.input_paths = input_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self): # no. of samples    \n",
    "        \n",
    "        return len(self.input_paths)\n",
    "    \n",
    "    def __getitem__(self, index): # as ndarray\n",
    "    \n",
    "\n",
    "        X, y = self.input_paths[index], self.target_paths[index]\n",
    "\n",
    "        #if transform: # retained as placeholder\n",
    "\n",
    "        return X, y\n",
    "    \n",
    "class EarlyStopping:\n",
    "\n",
    "    def __init__(self, patience=20):\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.patience_count = 0\n",
    "        self.bar_for_val_loss = 1e50\n",
    "        self.out_of_patience = False\n",
    "        \n",
    "    def __call__(self, current_val_loss, model, models_dir, model_name):\n",
    "        \n",
    "        if current_val_loss <= self.bar_for_val_loss:\n",
    "            self.bar_for_val_loss = current_val_loss\n",
    "            self.patience_count = 0\n",
    "        else:\n",
    "            self.patience_count += 1\n",
    "            if self.patience_count == self.patience:\n",
    "                #save_path = os.path.join(models_dir, '{}_checkpoint.h5'.format(args.build))\n",
    "                #torch.save(model.state_dict(), save_path)\n",
    "                self.out_of_patience = True\n",
    "    \n",
    "class Network:\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "\n",
    "    def train(self, input, target):\n",
    "        input, target = Variable(input), Variable(target)\n",
    "\n",
    "        input = input.float() # HOTFIX - change from double to float\n",
    "\n",
    "        # =====================forward======================\n",
    "        decoded = model(input.cuda(args.gpu)) if cuda else model(input)    # run batched input through the network\n",
    "        loss = loss_function(decoded, target.cuda(args.gpu))                 # loss function defined below (MSE)\n",
    "        # =====================backward=====================\n",
    "        loss.backward()                                     # backpropagate and compute new gradients\n",
    "        optimizer.step()                                     # apply updated gradients\n",
    "        # =======================log========================\n",
    "        optimizer.zero_grad()                                 # reset gradients from earlier training step\n",
    "        return loss.item()                                    # training loss\n",
    "\n",
    "    def validate(self, input, target):\n",
    "        input, target = Variable(input), Variable(target)\n",
    "\n",
    "        input = input.float() # HOTFIX - change from double to float\n",
    "\n",
    "        #if cuda:\n",
    "        #    input.cuda()\n",
    "        # =====================forward======================\n",
    "        decoded = model(input.cuda(args.gpu)) if cuda else model(input)        # run batched input through the network\n",
    "        loss = loss_function(decoded, target.cuda(args.gpu))                 # loss function defined below (MSE)\n",
    "        # =======================log========================\n",
    "        return loss.item()                                    # validation loss\n",
    "\n",
    "    def run(self):\n",
    "        for epoch in range(args.epochs):\n",
    "            train_loss, val_loss = [], []    # store training and validation loss over batch iterations\n",
    "            \n",
    "            # =====================TRAINING=====================\n",
    "            model.train()                                             # Set model for training\n",
    "            for input, target in train_dataloader:\n",
    "\n",
    "                # =============NON-CONVOLUTIONAL MODEL==============\n",
    "                if args.crop:\n",
    "                    idx = 0\n",
    "                    for i in range(int(np.floor((args.window_size-args.crop_size)/args.crop_shift))+1):\n",
    "                        _input, _target = transform.cropped_window_transform(input, target, idx=idx, scaling_factor=sample_length, length=args.crop_size)\n",
    "                        train_loss.append(self.train(_input, _target))\n",
    "                        idx += args.crop_shift\n",
    "                \n",
    "                # ===============CONVOLUTIONAL MODEL===============        \n",
    "                else:\n",
    "                    train_loss.append(self.train(input, target))        \n",
    "\n",
    "            # ====================VALIDATION====================\n",
    "            model.eval()                                            # Set model to evaluation for validation\n",
    "            \n",
    "            for input, target in val_dataloader:\n",
    "                if args.crop:\n",
    "                    idx = 0\n",
    "                    for i in range(int(np.floor((args.window_size-args.crop_size)/args.crop_shift))+1):\n",
    "                        _input, _target = transform.cropped_window_transform(input, target, idx=idx, scaling_factor=sample_length, length=args.crop_size)\n",
    "                        val_loss.append(self.validate(_input, _target))\n",
    "                        idx += args.crop_shift\n",
    "                else:\n",
    "                    val_loss.append(self.validate(input, target))    \n",
    "            # ========================LOG=======================\n",
    "            \n",
    "            log = 'epoch [{}/{}]\\ntraining loss: {:.10f}\\nvalidation loss: {:.10f}\\n'\n",
    "            print(log.format(epoch + 1, args.epochs, np.average(train_loss), np.average(val_loss)))\n",
    "            \n",
    "            self.train_loss.append(np.average(train_loss)) # store avg train loss for later plotting\n",
    "            self.val_loss.append(np.average(val_loss))  # store avg val loss for later plotting\n",
    "            \n",
    "            early_stopping(np.average(val_loss), model, models_dir, args.model)             # if validation loss decreases, save model and stop training\n",
    "            if early_stopping.out_of_patience:\n",
    "                print('Early stopping: no validation improvement for {} epochs.'.format(args.patience))\n",
    "                break\n",
    "            \n",
    "            scheduler.step()                                        # prompt scheduler step\n",
    "            \n",
    "        #model.load_state_dict(torch.load(os.path.join(models_dir, '{}_checkpoint.h5'.format(args.build))))            # if early stopping, load the last checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for fetching the data, plotting, saving outputs, and end-to-end running of baseline model.\n",
    "\n",
    "def write_to_file():\n",
    "\n",
    "    with open(\"decoded.csv\", 'w') as f:\n",
    "        wr = csv.writer(f, lineterminator = '\\n')    \n",
    "        for input, target in test_dataloader:\n",
    "            input, target = Variable(input), Variable(target)\n",
    "            input = input.float() # HOTFIX - change from double to float\n",
    "            # =====================forward======================\n",
    "            decoded = model(input.cuda(args.gpu)) if cuda else model(input) # decode\n",
    "            predicted, true = decoded.argmax(axis=1).cpu().numpy(), target.detach().cpu().numpy()\n",
    "            # ======================write=======================\n",
    "            # Change of plans: we'll simply print to screen rather than write to file:\n",
    "            print(\"Accuracy score: {}\".format(accuracy_score(true, predicted)))\n",
    "            print()\n",
    "            print(confusion_matrix(true, predicted))\n",
    "            print()\n",
    "            print(classification_report(true, predicted, target_names=transform.event_ids_merged.keys(),\n",
    "                zero_division=0))\n",
    "            print()\n",
    "            # for i in range(len(input)):\n",
    "            #     wr.writerow(decoded[i].tolist())    # write to file\n",
    "\n",
    "def plot_losses_over_time(model_name): # adapted from https://github.com/Bjarten/early-stopping-pytorch\n",
    "    \"\"\"\n",
    "    Plot losses over time for a given model. Was integrated as an argparse call, \n",
    "    but now requires a separate call (we used a different plotting in the end,\n",
    "    but I'll leave this in here for future use because it's pretty useful for future work.)\n",
    "    \"\"\"\n",
    "\n",
    "    # load saved training and validation losses from the trained FCN\n",
    "    d = np.load(\"{}_score.npy\".format(args.model))\n",
    "    train_loss, val_loss = [i[1] for i in d['train_loss']],[i[1] for i in d['val_loss']]\n",
    "    \n",
    "    # find position of lowest val loss; get max val; constrain plot\n",
    "    max_val = max(train_loss+val_loss)\n",
    "    min_val_idx = val_loss.index(min(val_loss))+1\n",
    "    train_loss, val_loss = train_loss[:min_val_idx+5], val_loss[:min_val_idx+5]\n",
    "    \n",
    "    # visualize the loss as the network trained\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
    "    plt.plot(range(1,len(val_loss)+1),val_loss,label='Validation Loss')\n",
    "\n",
    "    plt.axvline(min_val_idx, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
    "\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.ylim(0, max_val+.5*max_val) # consistant scale\n",
    "    plt.xlim(0, len(train_loss)+1) # consistant scale\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    fig.savefig('{}_loss_plot.png'.format(args.model), bbox_inches='tight')\n",
    "\n",
    "def get_data(path, decomposition='subband'):\n",
    "    \"\"\"\n",
    "    path is a list of (input,target) tuples, where input is the path\n",
    "    to the input data, and target is the path to the target data\n",
    "    \"\"\"\n",
    "\n",
    "    input_files, target_files = [], []\n",
    "    \n",
    "    for participant in path:\n",
    "        if args.id:\n",
    "            subject_id = re.findall(r'\\d\\d\\d\\d', participant[0])[0]\n",
    "            for sub in args.id.split():\n",
    "                if subject_id == sub:\n",
    "                    input_files.append(participant[0]) # eeg_path\n",
    "                    target_files.append(participant[1]) # annotations_path\n",
    "        else:\n",
    "            input_files.append(participant[0]) # eeg_path\n",
    "            target_files.append(participant[1]) # annotations_path\n",
    "\n",
    "    if args.debug:\n",
    "        input_files, target_files = input_files[:10], target_files[:10]\n",
    "\n",
    "    X, y = np.array([]), np.array([])\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "\n",
    "        try:\n",
    "            epochs = transform.epoch(input_files[i], target_files[i])\n",
    "\n",
    "            if decomposition=='subband':\n",
    "                _X = transform.subband_decomposition(epochs.get_data())\n",
    "            elif decomposition=='welch':\n",
    "                _X = transform.power_spectral_decomposition(epochs)\n",
    "            else:\n",
    "                _X = epochs.get_data()  # transform from epochs object to numpy array of shape (events, channels, time)\n",
    "\n",
    "            _y = epochs.events[:, 2]\n",
    "\n",
    "            if not X.any():\n",
    "                X = _X\n",
    "            else:\n",
    "                X = np.vstack((X,_X))\n",
    "            if not y.any():\n",
    "                y = _y\n",
    "            else:\n",
    "                y = np.hstack((y,_y))\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, random_state=args.seed)\n",
    "            \n",
    "            X_train, X_val, y_train, y_val = train_test_split(\n",
    "                X_train, y_train, train_size=train_size, random_state=args.seed)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    train_data = Dataset(X_train, y_train)\n",
    "    val_data = Dataset(X_val, y_val)\n",
    "    test_data = Dataset(X_test, y_test)\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "def get_available_device(max_memory=0.8):\n",
    "\n",
    "    GPUs = GPUtil.getGPUs()\n",
    "    freeMemory = 0\n",
    "    available=-1\n",
    "    for GPU in GPUs:\n",
    "        if GPU.memoryUtil > max_memory:\n",
    "            continue\n",
    "        if GPU.memoryFree >= freeMemory:\n",
    "            freeMemory = GPU.memoryFree\n",
    "            available = GPU.id\n",
    "\n",
    "    return available \n",
    "\n",
    "def intrasubject_RF_classifier():\n",
    "\n",
    "    transform = Transform()\n",
    "\n",
    "    # Fetch the data with `wget -r -N -c -np https://physionet.org/files/sleep-edfx/1.0.0/`\n",
    "    # we won't put this as an passable argument in the script; best it stays in the readme\n",
    "\n",
    "    path = os.path.join('.','physionet.org','files','sleep-edfx','1.0.0','sleep-cassette')\n",
    "\n",
    "    # OK, so, assuming that this script is at '.' (i.e at the top-level of the directory),\n",
    "    # the 'path' above has many pairs of EEG + annotations files. So, we're going to make\n",
    "    # a list of tuples containing these.\n",
    "\n",
    "    files = sorted(os.listdir(path))\n",
    "    files.remove('index.html') # the only file we want to ignore\n",
    "\n",
    "    psg_files = files[0::2] # polysomnogram files (electroencephalography; eeg data)\n",
    "    hypnogram_files = files[1::2] # hypnogram files (expert-labelled annotation data)\n",
    "\n",
    "    files = [*zip(psg_files, hypnogram_files)]\n",
    "    # Cool, so now we've done that...\n",
    "\n",
    "    n = len(files) # There are 153 subjects\n",
    "\n",
    "    subject_4001 = files[0] # for now we'll just take the first 10; taking all 8gb of data may be overkill...\n",
    "\n",
    "    eeg_path = os.path.join(path, subject_4001[0])\n",
    "    annotations_path = os.path.join(path, subject_4001[1])\n",
    "\n",
    "    # Let's get our baseline results. We'll use a Random Forest...:\n",
    "\n",
    "    eeg = mne.io.read_raw_edf(eeg_path) #, preload=True, stim_channel='auto')\n",
    "    annotations = mne.read_annotations(annotations_path)\n",
    "\n",
    "    # Map the channel (sensor) names to their data types\n",
    "    # (just ensures MNE knkows know to process these properly):\n",
    "    mapping = transform.mapping\n",
    "\n",
    "    eeg.set_annotations(annotations, emit_warning=False)\n",
    "    eeg.set_channel_types(mapping)\n",
    "\n",
    "    # Plot 1: first glance overview of the distribution of the sleep stages\n",
    "    eeg.plot(duration=60, scalings='auto')\n",
    "\n",
    "    # From annotations.description, we can see that we have 7 classes. One of\n",
    "    # these classes is the 'unknown' class ('Sleep stage ?'), so we'll desregard\n",
    "    # this and assign the others:\n",
    "\n",
    "    event_ids = transform.event_ids\n",
    "    # From Plot 1, we can see a hell of a lot of data for 'Sleep Stage W'\n",
    "    # (i.e. the person is a awake a hell of a lot more than they are asleep).\n",
    "    # Annotations.onset provides us with a list of start times for each sleep stage.\n",
    "    # So, to prevent any class balance issues, we'll top-and-tail the awake data, keeping\n",
    "    # only 10% of the awake data immediately before the first, and after the last,\n",
    "    # sleep stage.\n",
    "\n",
    "    first100 = annotations.onset[1]/100\n",
    "    last100 = (annotations.onset[-1]-annotations.onset[-2])/100\n",
    "    annotations.crop(annotations[1]['onset'] - first100, annotations[-2]['onset'] + last100)\n",
    "    \n",
    "    # Set the event ids:\n",
    "    eeg.set_annotations(annotations, emit_warning=False)\n",
    "\n",
    "    # events_from_annotations allows us to extract the relevant data for each\n",
    "    # sleep stage for the purposes of plotting data, etc.\n",
    "\n",
    "    events = mne.events_from_annotations(eeg, event_id=event_ids, chunk_duration=30.)\n",
    "\n",
    "    # Odd syntax, but this is how we're going to plot the 'overview' of the data.\n",
    "    fig = mne.viz.plot_events(events[0], event_id=event_ids, sfreq=eeg.info['sfreq'], first_samp=events[0][0][0])\n",
    "\n",
    "    # Retain plotted legend colors for later plots (great utility! will be using this much more in future!)\n",
    "    stage_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    # just for the purposes of plotting the PSD quickly, we'll only take a random 10 instances of each class:\n",
    "\n",
    "    # store = np.array([], dtype=np.int64).reshape(0,events[0].shape[1])\n",
    "    # for i in events[1]:\n",
    "    #     event = events[0][np.where(events[0][:,2]==events[1][i])]\n",
    "    #     event = event[np.random.choice(len(event), size=8, replace=False)]\n",
    "    #     store = np.vstack([store, event])\n",
    "\n",
    "    # EPOCHING! Super important: this is how we're going to extract the data chunks corresponding\n",
    "    # to the sleep stages.\n",
    "\n",
    "    # List of time differences between all sleep stages:\n",
    "    deltas = [abs(j-i) for i,j in zip(annotations.onset, annotations.onset[1:])]\n",
    "     # This is so that we only consider epochs less than the longest known stage (minus cps)\n",
    "    tmax = max(deltas) - (1. / eeg.info['sfreq'])\n",
    "\n",
    "    # Override; only chunk in steps of 0 to 29.99 secs; very important to do this so that all signal processing\n",
    "    # only applies in chunks with max size 3000. Otherwise, there'll be no windowing and the process will die :-(\n",
    "    # Note how the way we've implemented this means that a standard night's worth of EEG data roughly averages\n",
    "    # to window sizes of ~2.5 secs.\n",
    "    tmax = 30. - 1. / eeg.info['sfreq']\n",
    "\n",
    "    # Get all epochs:\n",
    "    # epochs = mne.Epochs(raw=eeg, events=events[0], event_id=event_ids, tmin=0., tmax=tmax, baseline=None)\n",
    "\n",
    "    event_ids_merged = {'Sleep stage W': 0,\n",
    "        'Sleep stage 1/2': 1,\n",
    "        'Sleep stage 3/4': 2,\n",
    "        'Sleep stage R': 3,\n",
    "        }\n",
    "\n",
    "    picks = ['eeg','eog','emg','resp','misc']\n",
    "\n",
    "    #rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # we're going to be lazy and use scikit-learn's KFold to get our train and test data cross-valisations:\n",
    "    kf = sklearn.model_selection.KFold(n_splits=5,random_state=42, shuffle=True)\n",
    "\n",
    "    #events_train, events_test = sklearn.model_selection.train_test_split(events[0], test_size=.1)\n",
    "    \n",
    "    y_test_store = np.array([], dtype=int)\n",
    "    y_pred_store = np.array([], dtype=int)\n",
    "    accuracy = 0\n",
    "\n",
    "    for train_idxs, test_idxs in kf.split(events[0]):\n",
    "\n",
    "        events_train = events[0][train_idxs]\n",
    "        events_test = events[0][test_idxs]\n",
    "\n",
    "        # Get train/test epochs:\n",
    "        epochs_train = mne.Epochs(raw=eeg,\n",
    "            events=events_train,\n",
    "            event_id=event_ids_merged,\n",
    "            tmin=0.,\n",
    "            tmax=tmax,\n",
    "            baseline=None,\n",
    "            picks=picks\n",
    "            )\n",
    "        \n",
    "        epochs_test = mne.Epochs(raw=eeg,\n",
    "            events=events_test,\n",
    "            event_id=event_ids_merged,\n",
    "            tmin=0.,\n",
    "            tmax=tmax,\n",
    "            baseline=None,\n",
    "            picks=picks)\n",
    "\n",
    "        # Train\n",
    "        y_train = epochs_train.events[:, 2]\n",
    "        y_test = epochs_test.events[:, 2]\n",
    "\n",
    "        epochs_train = transform.subband_decomposition(epochs_train.get_data())\n",
    "        epochs_train = epochs_train.reshape(epochs_train.shape[0], -1)\n",
    "\n",
    "        epochs_test = transform.subband_decomposition(epochs_test.get_data())\n",
    "        epochs_test = epochs_test.reshape(epochs_test.shape[0], -1)\n",
    "\n",
    "        # Train\n",
    "        rf.fit(epochs_train, y_train)\n",
    "\n",
    "        # Test\n",
    "        y_pred = rf.predict(epochs_test)\n",
    "\n",
    "        # Assess the results\n",
    "        accuracy += sklearn.metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "        y_test_store = np.hstack((y_test_store, y_test))\n",
    "        y_pred_store = np.hstack((y_pred_store, y_pred))\n",
    "\n",
    "    # Outputs:\n",
    "    print()\n",
    "    print(\"Accuracy score: {}\".format(accuracy/kf.get_n_splits(events[0])))\n",
    "    print()\n",
    "    print(confusion_matrix(y_test_store, y_pred_store))\n",
    "    print()\n",
    "    print(classification_report(y_test_store, y_pred_store, target_names=event_ids_merged.keys()))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-diamond",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================================================================\n",
    "# ============convenience variables for different participant combinations (thank you Tory!)=============\n",
    "# =======================================================================================================\n",
    "# full SC data set\n",
    "all_data = [4021,4022,4031,4032,4051,4052,4081,4082,4091,4092,4611,4612,4621,4622,4631,4632,4001,4002,4011,4012,4041,4042,4061,4062,4071,4072,4201,4202,4211,4212,4221,4222,4231,4232,4241,4242,4251,4252,4261,4262,4271,4272,4281,4282,4291,4292,4801,4802,4811,4812,4821,4822,4401,4402,4411,4412,4421,4422,4451,4452,4461,4462,4481,4482,4491,4492,4431,4432,4441,4442,4471,4472,4601,4602,4641,4642,4651,4652,4661,4662,4671,4672,4101,4102,4111,4112,4121,4122,4131,4141,4142,4181,4182,4191,4192,4731,4732,4741,4742,4751,4752,4761,4762,4151,4152,4161,4162,4171,4172,4301,4302,4311,4312,4321,4322,4341,4342,4351,4352,4362,4371,4372,4381,4382,4331,4332,4522,4531,4532,4571,4572,4581,4582,4591,4592,4501,4502,4511,4512,4541,4542,4551,4552,4561,4562,4701,4702,4711,4712,4721,4722,4771,4772]\n",
    "female_30 = [4021,4022,4031,4032,4051,4052,4081,4082,4091,4092]\n",
    "female_30_40 = [4001,4002,4011,4012,4041,4042,4061,4062,4071,4072]\n",
    "# note there is no data for people in thier 40s!\n",
    "female_40_50 = []\n",
    "female_50_60 = [4201,4202,4211,4212,4221,4222,4231,4232,4241,4242,4251,4252,4261,4262,4271,4272,4281,4282,4291,4292,4801,4802,4811,4812,4821,4822]\n",
    "female_60_70 = [4401,4402,4411,4412,4421,4422,4451,4452,4461,4462,4481,4482,4491,4492]\n",
    "female_70_80 = [4431,4432,4441,4442,4471,4472]\n",
    "female_80_90 = [4601,4602,4641,4642,4651,4652,4661,4662,4671,4672]\n",
    "female_90 = [4611,4612,4621,4622,4631,4632]\n",
    "\n",
    "male_30 = [4101,4102,4111,4112,4121,4122,4131,4141,4142,4181,4182,4191,4192]\n",
    "male_30_40 = [4151,4152,4161,4162,4171,4172]\n",
    "# note there is no data for people in thier 40s!\n",
    "male_40_50 = []\n",
    "male_50_60 = [4301,4302,4311,4312,4321,4322,4341,4342,4351,4352,4362,4371,4372,4381,4382]\n",
    "male_60_70 = [4331,4332,4522,4531,4532,4571,4572,4581,4582,4591,4592]\n",
    "male_70_80 = [4501,4502,4511,4512,4541,4542,4551,4552,4561,4562]\n",
    "male_80_90 = [4701,4702,4711,4712,4721,4722,4771,4772]\n",
    "male_90 = [4731,4732,4741,4742,4751,4752,4761,4762]\n",
    "\n",
    "# aggregations \n",
    "\n",
    "females = np.array(female_30+female_30_40+female_40_50+female_50_60+female_60_70+female_70_80+female_80_90+female_90)\n",
    "males = np.array(male_30+male_30_40+male_40_50+male_50_60+male_60_70+male_70_80+male_80_90+male_90)\n",
    "under_30 = female_30+male_30\n",
    "between_30_40 = female_30_40+male_30_40\n",
    "between_40_50 = female_40_50+male_40_50\n",
    "between_50_60 = female_50_60+male_50_60\n",
    "between_60_70 = female_60_70+male_60_70\n",
    "between_70_80 = female_70_80+male_70_80\n",
    "between_80_90 = female_80_90+male_80_90\n",
    "over_90 = female_90+male_90\n",
    "\n",
    "total_gender = [females,males]\n",
    "min_gender = min(map(len, total_gender))\n",
    "# excluded 40-50 as that's zero\n",
    "total_age = [under_30,between_30_40,between_50_60,between_60_70,between_70_80,between_80_90,over_90]\n",
    "sum_age = sum(map(len, total_age))\n",
    "min_age = min(map(len, total_age))\n",
    "total_gender_age = [female_30,female_30_40,female_50_60,female_60_70,female_70_80,female_80_90,female_90,male_30,male_30_40,male_50_60,male_60_70,male_70_80,male_80_90,male_90]\n",
    "min_gender_age = min(map(len, total_gender_age))\n",
    "\n",
    "for gender in total_gender:\n",
    "    random.shuffle(gender)\n",
    "random_females = females[:min_gender]\n",
    "random_males = males[:min_gender]\n",
    "\n",
    "for age in total_age:\n",
    "    random.shuffle(age)\n",
    "random_under_30 = under_30[:min_age]\n",
    "random_between_30_40 = between_30_40[:min_age]\n",
    "# not including 40-50 as there are none\n",
    "random_between_50_60 = between_50_60[:min_age]\n",
    "random_between_60_70 = between_60_70[:min_age]\n",
    "random_between_70_80 = between_70_80[:min_age]\n",
    "random_between_80_90 = between_80_90[:min_age]\n",
    "random_over_90 = over_90[:min_age]\n",
    "\n",
    "for gender_age in total_gender_age:\n",
    "    random.shuffle(gender_age)\n",
    "random_female_30 = female_30[:min_gender_age]\n",
    "random_female_30_40 = female_30_40[:min_gender_age]\n",
    "# not including 40-50 as there are none\n",
    "random_female_50_60 = female_50_60[:min_gender_age]\n",
    "random_female_60_70 = female_60_70[:min_gender_age]\n",
    "random_female_70_80 = female_70_80[:min_gender_age]\n",
    "random_female_80_90 = female_80_90[:min_gender_age]\n",
    "random_female_90 = female_90[:min_gender_age]\n",
    "random_male_30 = male_30[:min_gender_age]\n",
    "random_male_30_40 = male_30_40[:min_gender_age]\n",
    "# not including 40-50 as there are none\n",
    "random_male_50_60 = male_50_60[:min_gender_age]\n",
    "random_male_60_70 = male_60_70[:min_gender_age]\n",
    "random_male_70_80 = male_70_80[:min_gender_age]\n",
    "random_male_80_90 = male_80_90[:min_gender_age]\n",
    "random_male_90 = male_90[:min_gender_age]\n",
    "\n",
    "gender_buckets = [random_females,random_males]\n",
    "# not including 40-50 as there are none\n",
    "age_buckets = [random_under_30, random_between_30_40, random_between_50_60, random_between_60_70, random_between_70_80, random_between_80_90, random_over_90]\n",
    "gender_age_buckets = [random_female_30, random_female_30_40, random_female_50_60, random_female_60_70, random_female_70_80, random_female_80_90, random_female_90, random_male_30, random_male_30_40, random_male_50_60, random_male_60_70, random_male_70_80, random_male_80_90, random_male_90]\n",
    "\n",
    "# size breaks\n",
    "random.shuffle(all_data)\n",
    "one = all_data[:1]\n",
    "random.shuffle(all_data)\n",
    "ten = all_data[:10]\n",
    "random.shuffle(all_data)\n",
    "twenty = all_data[:20]\n",
    "\n",
    "size_breaks = [one, ten, twenty]\n",
    "\n",
    "# inter/ intra\n",
    "\n",
    "random.shuffle(all_data)\n",
    "one_intra = all_data[:1]\n",
    "clean_age_gender = gender_age_buckets = [random_female_30, random_female_30_40, random_female_50_60, random_female_60_70, random_female_70_80, random_female_80_90, random_female_90, random_male_30, random_male_30_40, random_male_50_60, random_male_60_70, random_male_70_80, random_male_80_90, random_male_90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-possible",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config.yml\n",
    "train: False\n",
    "test: True\n",
    "model: 'CNN'\n",
    "id: '4001, 4002'\n",
    "filter: 'multi_bandpass'\n",
    "normalisation: 'mean_variance'\n",
    "build: 'CNN'\n",
    "in_channels: \"(6,12,24)\"\n",
    "out_channels: \"(12,24,48)\"\n",
    "kernel_size: \"(1,6)\"\n",
    "pool_size: \"(1,2)\"\n",
    "stride: 2\n",
    "dilation: 1\n",
    "padding: \"(0,0)\"\n",
    "channels: 'all'\n",
    "frequency_bands: 'all'\n",
    "decomposition: 'subband'\n",
    "crop: '-f'\n",
    "window_size: 256\n",
    "window_shift: 246\n",
    "crop_size: 32\n",
    "crop_shift: 16\n",
    "dropout: .2\n",
    "batch_size: 256\n",
    "epochs: 1000\n",
    "learning_rate: 1e-4\n",
    "patience: 30\n",
    "seed: 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-retro",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "\n",
    "# ==================================================\n",
    "# =============softcoded default paths==============\n",
    "# ==================================================\n",
    "\n",
    "# I would hope that either a UNIX or Windows machine would be OK with\n",
    "# the data being in a sister dir, but we'll leave this here just in case.\n",
    "# The joys of groupwork and not knowing what other systems are in play.\n",
    "\n",
    "_ = {'nt':'.','posix':'.'}\n",
    "root = _[os.name] # change root depending on operating system\n",
    "\n",
    "# Fetch the data with `wget -r -N -c -np https://physionet.org/files/sleep-edfx/1.0.0/`\n",
    "# we won't put this as an passable argument in the script; best it stays in the readme\n",
    "\n",
    "path = os.path.join(root,'physionet.org','files','sleep-edfx','1.0.0','sleep-cassette')\n",
    "\n",
    "# OK, so, assuming that this script is at '.' (i.e at the top-level of the directory),\n",
    "# the 'path' above has many pairs of EEG + annotations files. So, we're going to make\n",
    "# a list of tuples containing these.\n",
    "\n",
    "files = sorted(os.listdir(path))\n",
    "files.remove('index.html') # the only file we want to ignore\n",
    "\n",
    "psg_files = files[0::2] # polysomnogram files (electroencephalography; eeg data)\n",
    "hypnogram_files = files[1::2] # hypnogram files (expert-labelled annotation data)\n",
    "\n",
    "files = [*zip([os.path.join(path, i) for i in psg_files],\n",
    "        [os.path.join(path, i) for i in hypnogram_files])]\n",
    "\n",
    "# Cool, so now we've done that...\n",
    "\n",
    "n = len(files) # There are 153 subjects\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models') \n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results') \n",
    "\n",
    "models_dir, results_dir = 'models', 'results'\n",
    "\n",
    "# ==================================================\n",
    "# ===============argparse options===================\n",
    "# ==================================================\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "mode = parser.add_mutually_exclusive_group()\n",
    "\n",
    "mode.add_argument(\"-t\", \"--train\", action=\"store_true\", help=\"train network from EEG data\", default=False)\n",
    "mode.add_argument(\"-c\", \"--test\", action=\"store_true\", help=\"use network to classify test EEG data\", default=True)\n",
    "\n",
    "# yaml config file:\n",
    "parser.add_argument('-config', help=\"configuration file *.yml\", type=str, required=False, default='config.yml')\n",
    "\n",
    "parser.add_argument(\"--debug\", action=\"store_true\", help=\"debug (only use first 10 data samples)\")\n",
    "\n",
    "# ============model architecture choice=============\n",
    "parser.add_argument(\"-m\", \"--model\",type=str,choices=Models().models,required=False,\n",
    "    help=\"Model architecture from one of: {}\".format(', '.join(Models().models)), default='CNN')\n",
    "\n",
    "# ========thinker-(in)dependent model choice========\n",
    "parser.add_argument(\"--id\", type=str,\n",
    "    help=\"Subject ID number(s) to train thinker-dependent model (default = thinker-independent model). Available IDs are: {}\".format(\n",
    "        [re.findall(r'\\d\\d\\d\\d',file[0])[0] for file in files]), default=\"4001 4002\")\n",
    "\n",
    "# =======convenience arguments for data paths=======\n",
    "parser.add_argument(\"-f\", \"--filter\", type=str, choices=['single_bandpass', 'multi_bandpass'], default='multi_bandpass')\n",
    "parser.add_argument(\"-n\", \"--normalisation\", type=str, choices=['min_max', 'mean_variance'], default='mean_variance')\n",
    "parser.add_argument(\"-b\", \"--build\", type=str, default='model') # optional descriptor for model build\n",
    "\n",
    "# ===========parameters for convolutions============\n",
    "parser.add_argument(\"--in_channels\", type=ast.literal_eval, default=\"(12,24,48)\")# Tuple written as a string; e.g. \"(2,3)\"\n",
    "parser.add_argument(\"--out_channels\", type=ast.literal_eval, default=\"(12,24,48)\")# Tuple written as a string; e.g. \"(2,3)\"\n",
    "parser.add_argument(\"--kernel_size\", type=ast.literal_eval, default=\"(1,6)\")# Tuple written as a string; e.g. \"(2,3)\"\n",
    "parser.add_argument(\"--pool_size\", type=ast.literal_eval, default=\"(1,2)\")\n",
    "parser.add_argument(\"--stride\", type=ast.literal_eval, default=2)\n",
    "parser.add_argument(\"--dilation\", type=ast.literal_eval, default=1)\n",
    "parser.add_argument(\"--padding\", type=ast.literal_eval, default=\"(0,0)\")\n",
    "\n",
    "# ===============parameters for data===============\n",
    "parser.add_argument(\"--channels\", default='all', choices=['all', 'psg_only', 'eeg_only'])\n",
    "parser.add_argument(\"--frequency_bands\", default='all', choices=['all','delta','theta','alpha','sigma','beta','gamma'])\n",
    "parser.add_argument(\"--decomposition\", default='subband', choices=['subband', 'welch'])\n",
    "parser.add_argument(\"--crop\", action=\"store_true\", default=False)\n",
    "\n",
    "# =========user-definable (hyper)parameters=========\n",
    "parser.add_argument(\"--window_size\", type=int, default=256)\n",
    "parser.add_argument(\"--window_shift\", type=int, default=246)    \n",
    "parser.add_argument(\"--crop_size\", type=int, default=32)\n",
    "parser.add_argument(\"--crop_shift\", type=int, default=16)\n",
    "parser.add_argument(\"--dropout\", type=float, default=.2)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=256)\n",
    "parser.add_argument(\"--epochs\", type=int, default=1000)\n",
    "parser.add_argument(\"--learning_rate\", type=float, default=1e-4)\n",
    "parser.add_argument(\"--patience\", type=int, default=30)\n",
    "parser.add_argument(\"--seed\", type=int, default=99)\n",
    "\n",
    "# ===============load argvs with yaml===============\n",
    "sys.argv = ['-f']\n",
    "args = parser.parse_args()\n",
    "\n",
    "#     if not args.args:  # args priority is higher than yaml\n",
    "#         opt = vars(args)\n",
    "#         args = yaml.load(open(args.config), Loader=yaml.FullLoader)\n",
    "#         opt.update(args)\n",
    "#         args = opt\n",
    "#     else:  # yaml priority is higher than args\n",
    "opt = yaml.load(open(args.config), Loader=yaml.FullLoader)\n",
    "opt.update(vars(args))\n",
    "_args = opt\n",
    "print(\"arguments: {}\".format(str(_args)))\n",
    "\n",
    "# ==================================================\n",
    "# ============hardcoded data parameters=============\n",
    "# ==================================================\n",
    "\n",
    "test_size = 0.1 # of all data, percentage for test set\n",
    "train_size = 0.9 # of the training data, the train/val split\n",
    "\n",
    "all_frequency_bands = ['delta','theta','alpha','sigma','beta','gamma']\n",
    "\n",
    "channels = {'all':['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal', 'EMG submental', 'Temp rectal'],\n",
    "            'psg_only':['EEG Fpz-Cz', 'EEG Pz-Oz', 'EOG horizontal', 'Resp oro-nasal'],\n",
    "            'eeg_only':['EEG Fpz-Cz', 'EEG Pz-Oz']}\n",
    "\n",
    "args.train = _args['train']\n",
    "args.test = _args['test']\n",
    "args.model = _args['model']\n",
    "args.id = _args['id']\n",
    "args.filter = _args['filter']\n",
    "args.normalisation = _args['normalisation']\n",
    "args.build = _args['build']\n",
    "args.in_channels = _args['in_channels']\n",
    "args.out_channels = _args['out_channels']\n",
    "args.kernel_size = _args['kernel_size']\n",
    "args.pool_size = _args['pool_size']\n",
    "args.stride = _args['stride']\n",
    "args.dilation = _args['dilation']\n",
    "args.padding = _args['padding']\n",
    "args.channels = _args['channels']\n",
    "args.frequency_bands = _args['frequency_bands']\n",
    "args.decomposition = _args['decomposition']\n",
    "args.crop = _args['crop']\n",
    "args.window_size = _args['window_size']\n",
    "args.window_shift = _args['window_shift']\n",
    "args.crop_size = _args['crop_size']\n",
    "args.crop_shift = _args['crop_shift']\n",
    "args.dropout = _args['dropout']\n",
    "args.batch_size = _args['batch_size']\n",
    "args.epochs = _args['epochs']\n",
    "args.learning_rate = _args['learning_rate']\n",
    "args.patience = _args['patience']\n",
    "args.seed = _args['seed']\n",
    "\n",
    "# ==================================================\n",
    "# ================dynamic parameters================\n",
    "# ==================================================\n",
    "\n",
    "args.channels = channels[args.channels] # set channels used\n",
    "args.frequency_bands = all_frequency_bands if args.frequency_bands == 'all' else [args.frequency_bands]\n",
    "sampling_rate, sample_length = 100, 1#len(args.frequency_bands)*len(args.channels) # Hz\n",
    "\n",
    "# ==================================================\n",
    "# =================network setup====================\n",
    "# ==================================================\n",
    "\n",
    "# Sanity check to see if we're using the GPU or not\n",
    "# We're training everything over Hex, so it should be OK,\n",
    "# but useful also if people are wanting to play on their home computers.\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "# Initialize model\n",
    "models = Models(**vars(args))\n",
    "\n",
    "input_size, model = models.get_model()\n",
    "\n",
    "print('\\nSanity check for current model params:')\n",
    "print(vars(models)['models'][vars(models)['model']])\n",
    "print('\\nSanity check for current model:')\n",
    "print(model)\n",
    "\n",
    "#device = torch.device(\"cuda:1\") # just leaving this here because some people were not playing 'nice'\n",
    "#model.to(device) # just leaving this here because some people were not playing 'nice'\n",
    "\n",
    "network = Network()\n",
    "\n",
    "args.gpu = get_available_device()\n",
    "\n",
    "if cuda:\n",
    "    model.cuda(args.gpu) # Woo! Cuda! :-)\n",
    "\n",
    "# Define loss function for multiclass classification:\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize optimizer & scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate, weight_decay=5e-4) # these are good values for the deep models\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=args.learning_rate, weight_decay=5e-4)\n",
    "restart_period = 5\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, restart_period, T_mult=1, eta_min=0, last_epoch=-1)\n",
    "\n",
    "# Initialize early stopping params\n",
    "early_stopping = EarlyStopping(patience=args.patience)\n",
    "\n",
    "# ==================================================\n",
    "# ===================data setup=====================\n",
    "# ==================================================\n",
    "\n",
    "transform = Transform(\n",
    "    model_name = args.model,\n",
    "    channels_transform = len(args.channels) < len(channels['all']),\n",
    "    frequency_bands_transform = len(args.frequency_bands) < len(all_frequency_bands),\n",
    "    eeg_indices = sorted([channels['all'].index(i) for i in channels['eeg_only']])\n",
    "    )\n",
    "\n",
    "train_data, val_data, test_data = get_data(files, decomposition=args.decomposition) # Get data from user-specified path\n",
    "train_sampler, val_sampler = RandomSampler(train_data), SequentialSampler(val_data)    # Samplers for training and validation batches\n",
    "# ==================================================\n",
    "\n",
    "if args.train:\n",
    "    train_dataloader = DataLoader(train_data, batch_size=args.batch_size, sampler = train_sampler) # online read of sampled minibatched training data\n",
    "    val_dataloader = DataLoader(val_data, batch_size=args.batch_size, sampler = val_sampler) # online read of sampled minibatched validation data\n",
    "    if os.path.isfile(os.path.join(models_dir, '{}_checkpoint.h5'.format(args.build))): # load in checkpointed model if training was inturrupted\n",
    "        model.load_state_dict(torch.load(os.path.join(models_dir, '{}_checkpoint.h5'.format(args.build))))\n",
    "\n",
    "    # train model\n",
    "    t = time.time()\n",
    "    network.run()\n",
    "    t = time.time() - t\n",
    "\n",
    "    # save model summary for visualisation\n",
    "    avg_train_loss = [('epoch {}'.format(i),'{}'.format(j)) for i,j in [k for k in enumerate(network.train_loss,1)]] # convenience data storage\n",
    "    avg_val_loss = [('epoch {}'.format(i),'{}'.format(j)) for i,j in [k for k in enumerate(network.val_loss,1)]] # convenience data storage\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = mystdout = StringIO()\n",
    "    pprint(model)\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    # get sample decoded output for evaluation statistics (normalised root mean square error, etc.)\n",
    "    model.eval()\n",
    "\n",
    "    input, target = next(iter(val_dataloader))\n",
    "    input, target = Variable(input), Variable(target)\n",
    "    input = input.float() # HOTFIX - change from double to float\n",
    "    input, target = input.cuda(args.gpu), target.cuda(args.gpu)\n",
    "\n",
    "    if args.crop:\n",
    "\n",
    "        idx = 0\n",
    "        #dims = models.transform_data(args.model, input, target, idx=idx, scaling_factor=sample_length, length=args.crop_size)[1].size()\n",
    "        input_stack, target_stack = np.array([]), np.array([])\n",
    "        for i in range(int(np.floor((args.window_size/args.crop_size)))):\n",
    "            _input, _target = transform.cropped_window_transform(input, target, idx=idx, scaling_factor=sample_length, length=args.crop_size)\n",
    "            _input, _target = torch.tensor(model(Variable(_input))).clone().detach().cpu().numpy(), _target.detach().cpu().numpy()\n",
    "\n",
    "            if not input_stack.any():\n",
    "                input_stack = _input\n",
    "            else:\n",
    "                input_stack = np.vstack((input_stack,_input))\n",
    "            if not target_stack.any():\n",
    "                target_stack = _target\n",
    "            else:\n",
    "                target_stack = np.hstack((target_stack,_target))\n",
    "            idx += args.crop_size\n",
    "\n",
    "        predicted, true = input_stack.argmax(axis=1), target_stack\n",
    "\n",
    "    else:\n",
    "\n",
    "        decoded = torch.tensor(model(input)).clone().detach().cpu().numpy() # detach and copy to cpu to convert to numpy array\n",
    "        predicted, true = decoded.argmax(axis=1), target.detach().cpu().numpy()\n",
    "\n",
    "    args.window_size, args.window_stride = args.crop_size, args.crop_shift # amend values following sample decoding\n",
    "\n",
    "\n",
    "    # Save model parameters for tuning and plotting\n",
    "    summary = {\n",
    "        'model': args.model,\n",
    "        'summary': mystdout.getvalue(),\n",
    "        'channels':args.channels,\n",
    "        'freqs': args.frequency_bands,\n",
    "        'time': t,\n",
    "        'windowsize': args.window_size,\n",
    "        'windowstride': args.window_stride,\n",
    "        'randomseed': args.seed,\n",
    "        'epochs': len(avg_train_loss)-args.patience,\n",
    "        'trainloss': avg_train_loss[:-args.patience],\n",
    "        'valloss': avg_val_loss[:-args.patience],\n",
    "        'trainlossall': avg_train_loss,\n",
    "        'vallossall': avg_val_loss,            \n",
    "        'val': avg_val_loss[:-args.patience][-1][1],\n",
    "        'accuracy': accuracy_score(true, predicted),\n",
    "        'batchsize': args.batch_size,\n",
    "        'lr': args.learning_rate,\n",
    "        'patience': args.patience,\n",
    "        'dropout': args.dropout,\n",
    "        'inputsize': input_size,\n",
    "        'kernelsize': args.kernel_size,\n",
    "        'poolsize': args.pool_size,\n",
    "        'stride': args.stride,\n",
    "        'dilation': args.dilation,\n",
    "        'padding': args.padding,\n",
    "        'filter': args.filter,\n",
    "        'normalisation': args.normalisation,\n",
    "        }\n",
    "\n",
    "    print(\"Accuracy score: {}\".format(accuracy_score(true, predicted)))\n",
    "    print()\n",
    "    print(confusion_matrix(true, predicted))\n",
    "    print()\n",
    "    print(classification_report(true, predicted, target_names=transform.event_ids_merged.keys(),\n",
    "        zero_division=0))\n",
    "    print()\n",
    "\n",
    "    savepath = os.path.join(results_dir, '{}_'.format(args.build))  #datetime.now().strftime('%m%d%H%M')))\n",
    "    np.save(savepath + 'score', np.array([summary]))\n",
    "    np.save(savepath + 'pred', predicted)\n",
    "    np.save(savepath + 'true', true)\n",
    "\n",
    "    # save final model state params, remove checkpoint\n",
    "    torch.save(model.state_dict(), os.path.join(models_dir, '{}.h5'.format(args.build))) # save model if number of epochs have run to zero\n",
    "    #os.remove(os.path.join(models_dir, '{}_checkpoint.h5'.format(args.build))) # remove temporary model checkpoint\n",
    "\n",
    "if args.test: # raw decoded - requires postprocessing argmax step\n",
    "    test_dataloader = DataLoader(test_data, batch_size=args.batch_size, shuffle=False) # Online read of unshuffled minibatched data\n",
    "    model.load_state_dict(torch.load(os.path.join(models_dir, '{}.h5'.format(args.build)))) # Load model from trained CNN\n",
    "    model.eval() # Set model to evaluation before running inference\n",
    "    write_to_file()\n",
    "    \n",
    "###############\n",
    "#### NOTE! ####\n",
    "###############\n",
    "\n",
    "# I've never used yaml before; this works on my local machine, but I'm not confident that it translates to other\n",
    "# machines easily. If you are struggling to run this .ipynb file, please use the supplied .py script instead,\n",
    "# which was used throughout the entire process and runs robustly on HEX (this .ipynb file is a translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
